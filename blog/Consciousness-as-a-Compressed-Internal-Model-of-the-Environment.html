<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>James Wiles Blog</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kimeiga/bahunya/dist/bahunya.min.css">
    <script src="https://cdn.jsdelivr.net/npm/marked@16/lib/marked.umd.min.js"></script>
    <script data-goatcounter="https://synetic.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
</head>

<body>
    <header>
        <nav>
            <a href="/">James Wiles Blog</a>
        </nav>
    </header>
    <main id="content"></main>
    <pre id="markdown" style="display: none">
# Consciousness as a Compressed Internal Model of the Environment
*James K. Wiles | 2021-04-07 (updated 2024-06-23))*

>"So it's compressing all the time the stuff that frequently appears. There is one thing, that appears all the time when the agent is interacting with its environment which is the agent itself. So just for data compression reasons it is extremely natural for this recurrent network to come up with little subnetworks that stand for the properties of the agent ... So just as a side effect of data compression during problem solving you have internal self models. Now you can use this model of the world to plan your future... Whenever it wakes up these little subnetworks that stand for itself then it is thinking about itself and it is exploring mentally the consequences of its own actions and now you tell me what is still missing in the gap to consciousness." - Juergen Schmidhuber

A living system differentiates itself from the environment, and in order to survive needs to communicate/interact with the environment by taking in and, optionally, giving out information. The better the system can manage the entropy of the environment the better it can survive, and to know what to do in the environment it builds an internal representation of the environment, as a mental model [1]. This allows the system to run scenarios on the model internally instead of exposing itself to the environment every time it needs to guess about the future. When a preferred internal scenario is chosen it can then do those actions on the outside world. These internal models are obviously compressed versions of environment. The environment is too big to fully replicate internally, so the better the compression the more information of the environment can be modelled by the system's limited internal processing capacity. This might be why compression is often said to be linked to intelligence.

Science can be thought of as a history of creating and improving on compressed representations of reality, measured by its ability to balance how "lossless" the information is versus the compressed size of the model.

Perhaps consciousness is, in effect, the feeling of you modelling yourself inside the internal scenarios you are running.

![simple compressed models](/blog/images/compressed_system_models.png)
*A tree, an animal, and a person located in the external environment separated by a boundary. Within the boundary we have an internal environment with various models of the external environment. Importantly, this internal environment also contains the observer doing the modeling, which can recursively model itself (or other observers doing the same). The model that offers the most survival value is the one that has the highest accuracy of important observations, with the least amount of compute/memory required to run/maintain the model (the best compression [2]).*

A metaphysical question then logically arises: What do you mean by "you" modeling "_you_"?

The answer is that it depends on what you mean by "you" - and this is the hard part - because you, to some degree, you are also your environment.

Here is a formulation of three nested levels to which one could conceptualize 'you' being located:

1. **Your mind**
   Primarily located in your pre-frontal cortex and often referred to as your conscious mind.
   This is the intelligent subset of your neural network that generates the self-modelling imagination often felt as consciousness described above. If your consciousness models this, it could be described as your _conscience being conscious of consciousness_.

2. **Your brain**
   This encompasses the rest of your neural network, and is not necessarily aware of itself. This could be considered your unconscious mind. When your consciousness models this, it is conscious of thinking. Here thinking is a superset of consciousness, and the brain capable of thinking about thinking only implies it _could_ be capable of consciousness.

3. **Your body**
   The living organism housing the brain. Your body physically interacts with its’ environment and it can chemically affect it’s internal neural network with neurochemicals and other signals. It also does some pre-processing of information before it enters the brain. Your consciousness models this as an agent that might or might not be able to think.

These systems above can be further nested into networks, starting with those which most immediately affect, and are affected by, them. For example, consider things like possessions: the clothing you are wearing or the vehicle you are driving. Additionally, "you" could be you as a person and the people you influence. "You" could be invading another country, and as such, "you" could be an entire society of people.

The degree of “_youness”_ might be correlated with a system's conscious ability to be conscious. Another way to think about this is if you suppose that a society could be conscious, then that society might have the ability to create models and run scenarios that involve itself. However, it might not necessarily model the consciousness of the individual people that make up the society. This means a society thinking about itself, more accurately views itself as a 'you' than does the people within it viewing the society as 'them'.

![simple society model](/blog/images/society_modeling.png)
*This image depicts an ensemble of observers, each with their own consciousness, together forming a collective consciousness. This depiction shows an inside group of people, separated by a boundary from an outside group of people. This ensemble model of models can emulate much of the individual consciousness of a single human, given that it has sufficient components to form a consciousness.*

Ultimately, the system that models itself the best is, to itself, the most 'you'. It can actually be whatever the ‘you’ considers itself to be.

Maybe the degree of consciousness is the degree of accuracy in self-modelling behavior, with the "self" being which ever system the models are embedded in for which the model is most accurately modelling itself.

Perhaps the degree of consciousness correlates with the accuracy of the ‘self’-modeling behavior, where 'self' refers to any system that embeds models and most accurately models itself.

References:
[1] Definition of a model: A representation of a system that can be used to gain information about the system without interacting with that system directly. This implies that the model can be manipulated or examined in ways that allow an observer to gather information about the system that direct interaction would not permit or would be too risky. The accuracy and amount of the additional information gathered, relative to the amount of energy needed to create and manipulate the model, is a measure of how good the model is. For example, a compressed representation that requires less energy for analysis while maintaining the same predictive powers as a larger model, has more efficiency and provides ability for greater survival fitness.

[2] The ability to compress could be one aspect of intelligence and it can be argued that higher intelligence is correlated to higher levels of consciousness. Some other aspects could be speed, scale, and accuracy of running simulated predictions of the models.

Further reading:
Bertschinger, Nils & Olbrich, Eckehard & ay, Nur. (2006). Information and closure in systems theory. German Workshop on Artificial Life <7, Jena, July 26 - 28, 2006>: Explorations in the complexity of possible life, 9-19 (2006). 

Chang AYC, Biehl M, Yu Y and Kanai R (2020) Information Closure Theory of Consciousness. _Front. Psychol._ 11:1504. doi: 10.3389/fpsyg.2020.01504

    </pre>
    <script>
        document.getElementById('content').innerHTML = marked.parse(document.getElementById('markdown').textContent);
    </script>
    <footer>
        <p>visitors: <span id="visitors"></span></p>
    </footer>
    <script>
        fetch(`https://synetic.goatcounter.com/counter/${encodeURIComponent(location.pathname)}.json`)
            .then(res => res.json()).then(data => document.querySelector('#visitors').textContent = data.count);
    </script>
</body>

</html>
